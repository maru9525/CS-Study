# Operatin System(운영체제)

[TOC]

## 프로세스와 스레드

- **프로그램** : 파일 단위로 저장 장치에 저장되어 있으며, 아직 실행되지 않은 상태의 코드 덩어리를 의미한다.
- **프로세스** : 실행 중인 프로그램이다. 프로그램을 실행하기 위해서는 주소 공간, 파일, 메모리 등이 필요한데 운영체제로부터 이런 것들을 할당 받은 프로그램을 프로세스라고 부른다.
- **스레드** : 프로세스의 실행 단위이다. 같은 프로세스 내에 있는 스레드끼리는 프로세스의 자원을 공유할 수 있다.

### 프로세스(Process)

프로세스는 운영체제로부터 메모리 공간을 할당 받아 실행 중인 프로그램이다.

**프로세스에 할당되는 메모리 영역**

> 코드(Code), 데이터(Data), 힙(Heap), 스택(Stack) 영역

- **코드 영역** : 프로세스가 실행할 코드가 기계어의 형태로 저장된 공간이다.(컴파일 타임에 결정, Read-Only)
- **데이터 영역** : 전역 변수, static 변수 등이 저장된 공간이다. 전역 변수. static 변수를 참조한 코드는 컴파일하고 나면 데이터 영역의 주소 값을 가르킨다.(컴파일 타임에 결정, Read-Write: 실행 도중 변경 가능)
- **힙 영역** : 프로그래머가 관리하는 메모리 영역으로, 힙 영역에 메모리를 할당하는 것을 동적 할당이라고 한다.(런타임에 결정, 스택보다 할당할 수 있는 메모리 공간이 많으나 데이터 읽고 쓰기가 느림)
- **스택 영역** : 함수 안에서 선언된 지역변수, 매개변수, 리턴값, 복귀 주소 등이 저장된다. 스택의 LIFO 방식에 따라 함수 호출 시 기록하고 종료되면 제거한다. (컴파일 타임에 결정, 정해진 크기가 있으므로 stack overflow 에러 발생 가능)

프로세스 제어 블록 (Process Control Block, PCB)

PCB는 특정 프로세스에 대한 정보를 담고 있는 운영체제의 자료구조이다. 프로세스는 운영체제의 스케줄링 알고리즘에 따라 CPU를 할당받는다. 작업을 진행하다가 프로세스 전환이 발생하면 하던 일을 저장하고 CPU를 반환해야 한다. 그리고 나중에 스케줄링에 의해 재실행되었을 때 이전에 어디까지 작업이 진행되었는지 그 정보를 알아야 한다. 그 정보가 담긴 공간이 PCB이다. 프로세스 생성과 동시에 그 프로세스의 고유한 PCB도 함께 생성된다.

**PCB에 저장되는 정보**

- 프로세스 식별자(Process ID, PID) : 프로세스 식별번호
- 프로세스 상태 : new, ready, running, waiting, terminated 등의 상태를 저장
- 프로그램 카운터 : 프로세스가 다음에 실핼할 명령어의 주소
- CPU 레지스터 : Accumulator, Index Register, 범용 레지스터 등
- CPU 스케줄링 정보 : 프로세스 우선순위, 최종 실행 시각, CPU 점유 시간 등
- 메모리 관리 정보 : Page table, Segment table 등
- 계정 정보 : CPU 사용 시간, 제한 시간, 계정 정보 등
- 입출력 상태 정보 : 프로세스에 할당된 입출력 장치, 개방된 파일 목록 등



### 스레드(Thread)

스레드는 프로세스를 구성하는 독립적인 실행 단위이다. 스레드는 같은 프로세스 내 다른 스레드와 메모리 영역을 공유 할 수 있다.

- 스레드도 하나의 실행 흐름이므로 실행과 관련된 데이터가 필요하다.
  - 독립적 : 각 스레드는 자신만의 고유한 **스레드ID, 프로그램 카운터(PC), 레지스터 집합, 스택 영역**을 가진다.
  - 공유 : 그리고 **속한 프로세스 내의 코드/데이터/힙 영역과 기타 운영체제 자원 (열린 파일, 신호 등)**을 다른 스레드와 공유한다.
- 각 스레드는 스택 영역을 통해 독립적인 실행 흐름을 가진다.
- 스레드는 프로세스 메모리 영역을 공유하기 때문에 어떤 스레드 하나에서 오류가 발생하면 같은 프로세스 내의 다른 스레드 모두가 강제로 종료된다. (프로세스는 한 프로세스가 강제 종료되어도 공유 자원을 손상시키는 경우가 아니라면 다른 프로세스에게 영향을 주지 않는다.)

**스택을 스레드마다 독립적으로 할당하는 이유**

스택은 함수 호출 시 전달되는 인자, 되돌아갈 주소값 및 함수 내에서 선언하는 변수 등을 저장하기 위해 사용되는 메모리 공간이므로 스택 메모리 공간이 독립적이라는 것은 독립적인 함수 호출이 가능하다는 것이고 이는 독립적인 실행 흐름이 추가되는 것이다. 따라서 스레드의 정의에 따라 독립적인 실행 흐름을 추가하기 위한 최소 조건으로 독립된 스택을 할당한다.

**PC Register 를 스레드마다 독립적으로 할당하는 이유**

PC 값은 스레드가 명령어의 어디까지 수행하였는지를 나타나게 된다. 스레드는 CPU를 할당받았다가 스케줄러에 의해 다시 선점당한다. 그렇기 떄문에 명령어가 연속적으로 수행되지 못하고 어느 부분까지 수행했는지 기억할 필요가 있다. 따라서 PC 레지스터를 독립적으로 할당한다.

## 멀티 프로세스와 멀티 스레드

### 멀티 프로세스(Multi-Process).

여러 개의 프로세스를 동시에 수행하는 것이다.

> 프로세스는 부모-자식 관례라고 해도 자신만의 메모리 영역을 가지게 되며, 공유되는 메모리 영역 없이 독립적인 구조를 가진다.

**크롬 브라우저의 멀티 프로세스 구조**

대부분의 브라우저는 탭 브라우징을 지원한다. 만일 브라우저가 멀티 프로세스 구조를 가지지 않는다면, 어떤 탭의 웹 어플리케이션이 비정상 종료되었을 때 다른 모든 탭을 포함한 전체 프로세스가 종료될 것이다.

구글의 크롬 브라우저는 멀티 프로세스 구조를 가지고 있다. 브라우저의 각 탭은(Renderer) 프로세스이며, 이들은 각작 독립적으로 실행된다. 하나의 웹 사이트가 비정상 종료되어도 다른(Renderer) 프로세스는 영향을 받지 않는다.

크롬은 다음과 같은 3가지 유형의 프로세스르 지원한다.

- **브라우저 프로세스** : 사용자 인터페이스와 디스크 및 네트워크 I/O를 관리한다. 크롬이 시작되면 새 브라우저 프로세스가 생성된다.
- **Renderer 프로세스** : 웹 페이지 렌더링을 위한 로직(HTML, JavaScript, 이미지 등 처리)을 포함한다. 이 때, 새 탭에서 열리는 각 웹사이트에 대해 새 Renderer 프로세스가 생성되므로 여러 프로세스가 동시에 활성화 될 수 있다.
- **플러그인 프로세스** : Flash 또는 QuickTime과 같은 각 플러그인 유형에 대해 플러그인 프로세스가 생성된다. 플로그인 프로세스에는 플러그인에 대한 코드와 연관된 Renderer, 브라우저 프로세스와 통신할 수 있도록 하는 추가 코드가 포함되어 있다.

**멀티 프로세스의 통신 방법**

독립적인 메모리 영역을 가지는 프로세스끼리도 통신하는 방법이 있다. 데이터를 교환하기 위해서 IPC(Inter-Process Communication) 메커니즘이 필요하다. IPC에는 **공유 메모리(shared memory)**와 **메시지 전달(message passing)**의 두가지 모델이 있다.

- 공유 메모리 : 프로세스가 공유하는 메모리 영역이 설정되며, 각 프로세스는 공유 영역에서 데이터를 읽고 쓰는 방식으로 정보를 교환할 수 있다.
- 메시지 전달 : 프로세스 간 메시지를 교환하며 통신한다.

**멀티 프로세스의 장점**

- 독림된 구조를 가지기 때문에 안정성이 높다.
- 하나의 프로세스가 비정상적으로 종료되어도 자식 프로세스 이외의 다른 프로세스들은 아무런 영향을 받지 않는다.

**멀티 프로세스의 단점**

- 독립된 메모리 영역을 가지고 있기 때문에 Context Switching 을 위한 오버헤드(캐시 초기화 등)가 발생한다.
- Context Switching이 빈번하게 일어나면 성능 저하를 유발할 수 있다.



### 멀티 스레드(Multi-Thread)

한 프로세스에서 여러 개의 쓰레드를 동시에 수행하는 것이다.

![image-20211011224151513](OS.assets/image-20211011224151513.png)

**멀티 스레드의 장점**

- **응답성**이 좋아진다. 단일 스레드를 사용하면 그 작업이 완료 될때까지 응답을 기다려야 한다. 멀티 스레드를 사용함으로서 응답성을 향상 시킬 수 있다.
- **자원을 공유**할 수 있다. 프로세스는 공유 메모리 및 메시지 전달과 같은 기술을 통해서만 자원을 공유할 수 있다.하지만 스레드는 기본적으로 자신이 속한 프로세스의 자원을 공유하기 때문에 동일한 주소 공간 내에서 여러 스레드를 가질 수 있다.
- **비용이 적다**. 스레드는 자신이 속한 프로세스의 자원을 공유하므로 스레드 생성과 Context-Switching 비용이 더 적다.

**멀티 스레드의 단점**

- 스레드는 프로세스 내 자원을 공유하기 때문에 스레드 하나에서 오류가 발생하면 같은 프로세스 내의 모든 스레드가 종료될 수 있다.
- 공유 자원에 대한 동기화 문제를 고려해야 한다.



## 캐시

캐시란, 자주 사용하는 데이터나 값을 미리 복사해 놓는 임시 장소를 가리킨다. 캐시는 저장 공간이 작고 비용이 비싼 대신, 데이터를 미리 복사해 놓기 때문에 계산이나 접근 시간을 대폭 줄여 더 빠른 속도록 데이터에 접근할 수 있다.

**캐시는 아래의 데이터의 경우에 사용하면 좋다**

1. 업데이트는 자주 발생하지 않는 데이터
2. 반복적으로 동일한 결과를 돌려주는 경우
3. 자주 조회되는 데이터

- 결국 캐시는 지속적으로 DBMS 혹은 서버에 요청하는 것이 아닌, 메모리에 데이터를 저장하였다가 불러다 쓰는 것을 의미한다.

**지역성**

CPU에서 명령어를 수행하며 매번 캐시 메모리를 참조하게 되는데, 이때 Hit rate가 지역성을 갖는다. 지역성이란? 프로세스들이 기억장치 내의 정보를 균일하게 액세스 하는 것이 아니라, 어느 순간에 특정 부분을 집중적으로 참조하는 것을 말한다. 지역성은 메모리의 위치와 접근 시간에 따라서 공간적, 시간적인 특성을 보인다.

**공간적 지역성**

한 번 참조한 메모리의 옆에 있는 메모리를 참조하게 되는 성질을 말한다. 

- Array라는 일정한 메모리 공간을 순차적으로 항다받아 사용할 때, 공간 할당을 연속적으로 받게 된다. 이 Array 메모리가 사용되어 질 때 연속적으로 사용될 가능성이 높아진다.

**시간적 지역성**

한 번 참조된 주소의 내용은 곧 다음에 다시 참조된다는 특성을 말한다.

- 반복문 사용 시 특정 메모리 값으로 선언된 부분을 반복하여 접근하게 된다.

**Local Cache vs Global Casche**

또한 캐시는 하드웨어가 아닌, 서버의 기준으로 로컬 캐시와 글로벌 캐시로 나뉜다. 로컬 캐시와 글로벌 캐시를 알맞게 선택하여 사용할 경우, 시스템의 성능을 높일 수 있다.

**Local Cache**

1. 서버마다 캐시를 따로 저장한다.
2. 다른 서버의 캐시를 참조하기 어렵다.
3. 서버 내에서 작동하기 때문에 속도가 빠르다.
4. 로컬 서버 장비의 리소스를 이용한다.(리소스 : 메모리, 디스크)

**Global Cache**

1. 여러 서버에서 캐시 서버에 접근하여 참조 할 수 있다.
2. 별도의 캐시 서버를 이용하기 때문에 서버 간 데이터 공유가 쉽다.
3. 네트워크 트래픽을 사용해야 해서 Local Cache보다 느리다.
4. 데이터를 분산하여 저장할 수 있다.



## 교착상태

교착상태는 상호 배제에 의해 나타나는 문제점으로, 둘 이상의 프로세스들이 자원을 점유한 상태에서 서로 다른 프로세스가 점유하고 있는 자원을 요구하며 무한정 기다리는 현상이다.

**교착상태 발생의 필요 충분 조건**

교착상태가 발생하기 위해서는 다음의 네 가지 조건이 충족되어야 하는데, 하나라도 충족되지 않으면 교착상태가 발생하지 않는다.

1. 상호배제(Mutual Exclusion) : 한 번에 한 개의 프로세스만이 공유 자원을 사용할 수 있어야 한다.
2. 점유와 대기(Hold and Wait) : 최소한 하나의 자원을 점유하고 이씅면서 다른 프로세스에 할당되어 사용되고 있는 자원을 추가로 점유하기 위해 대기하는 프로세스가 있어야 한다.
3. 비선점(Non-preeemption) : 다른 프로세스에 할당된 자원은 사용이 끝날 때까지 강제로 빼앗을 수 없어야 한다.
4. 환형 대기(Circular Wait) : 공유자원을 사용하기 위해 대기하는 프로세스들이 원형으로 구성되어 있고, 자신에게 할당된 자원을 점유하면서 앞이나 뒤 프로세스의 자원을 요구해야 한다.

### 교착상태를 막을 방법은 없을까 ?

**예방기법(Prevention)**

교착상태가 발생하지 않도록 사전에 시스템을 제어하는 방법으로, 교착상태 발생의 네 가지 조건 중에서 어느 하나를 제거하는 방법이다. 자원 낭비가 가장 심한 기법이다.

1. 상호 배제 부정 : 한 번에 여러개의 프로세스가 공유 자원을 사용할 수 있게 한다.
2. 점유 및 대기 부정 : 프로세스가 실행되기 전 필요한 모든 자원을 할당하여 프로세스 대기를 없애거나, 자원이 점유되지 않은 상태에서만 자원을 요구한다.
3. 비선점 부정 : 자원을 점유하고 있는 프로세스가 다른 자원을 요구할 때 점유하고 있는 자원을 반납하고, 요구한 자원을 사용하기 위해 기다리게 한다.
4. 환형 대기 부정 : 자원을 선형 순서로 분류하여 고유번호를 할당하고, 각 프로세스는 현재 점유한 자원의 고유 번호보다 앞이나 뒤 어느 한쪽 방향으로만 자원을 요구한다.

**회피기법(Avoidance)**

교착상태가 발생할 가능성을 배제하지 않고, 교착상태가 발생하면 적절히 피해나가는 방법으로, 은행원 알고리즘이 사용된다.

>```
>1. 은행원 알고리즘은 다익스트라가 제안한 기법으로, 은행에서 모든 고객의 요구가 충족되도록 현금을 할당하는데서 유래한 기법
>2. 각 프로세스에게 자원을 할당하여 교착상태가 발생하지 않으며, 모든 프로세스가 완료될 수 있는 상태를 안전 상태(safe state)라고 하며, 교착상태가 발생할 수 있는 상태를 불안전 상태(unsafe state)라고 함
>3. 은행원 알고리즘을 적용하기 위해서는 자원의 양과 프로세스 수가 일정해야 함
>4. 은행원 알고리즘은 프로세스의 모든 요구를 유한한 시간안에 할당하는 것을 보장함
>```

**발견기법(Detection)**

시스템에 교착상태가 발생했는지 점검하여 교착상태에 있는 프로세스와 자원을 발견하는 기법이다. 발견 후엔 교착상태 회복(Recovery) 직업을 수행하므로 발견기법과 회복기법을 함께 쓴다.(Detection & Recovery)

**회복기법(Recovery)**

교착상태를 일으킨 프로세스를 종료하거나, 교착상태의 프로세스에 할당된 자원을 선점하여 프로세스나 자원을 회복하는 것을 의미한다. 크게 프로세스 종료와 자원 선택으로 나뉜다.

1. **프로세스 종료**

프로세스 하나를 임의로 종료하여 교착상태를 해결하는 방법이다. 두 가지의 방법을 사용할 수 있다.

- 첫번째, 교착상태 프로세스를 모두 중지한다. 상당히 큰 비용이 들어가지만 단순하다.
- 두번째, 교착상태가 제거될 때까지 한 프로세스씩 중지한다. 각 프로세스가 중지될 때마다 교착상태를 확인해야하기 때문에, 상당한 오버헤드를 유발한다.

2. **자원 선점**

교착상태가 깨질 때까지 프로세스로부터 자우너을 계속적으로 선점해 다른 프로세스에게 주어야 한다. 따라서 다음 사항들을 꼭 고려해야 한다.

- **희생자 선택** : 어떤 자원과 프로세스가 선점될 것인가를 고민한다. 비용을 최소화 하기 위해 교착상태 프로세스가 점유하고 있는 자원의 수, 교착상태 프로세스가 지금까지 실행하는데 소요한 시간과 같은 변수를 고려하여 희생자를 선택한다.
- **롤백** : 만약 특정 프로세스 자원을 강제로 방출하고 선점했다면, 그 프로세스를 어떻게 처리할 것인지 고민해야 한다. 가장 안전한 방법은 프로세스를 중지하고 재시작한느 롤백이다.
- **기아 상태** : 계속해서 특정 프로세스의 자원을 강제로 방출시켜 선점을 시켜주면, 그 프로세스는 계속해서 희생자가 될 확률이 높아지고, 영원히 실행이 완료되지 못하는 기아상태에 빠질 수 있다. 따라서 프로세스에 롤백 횟수 제한을 두는 등, **프로세스가 한정된 시간에만 희생자로 선정된다는 것을 반드시 보장해야한다.**

## CPU 스케줄러

스케줄링 대산은 Ready Queue에 있는 프로세스들이다.



### FCFS(First Come First Served)

**특징**

- 먼저 온 고객을 먼저 서비스해주는 방식, 즉 먼저 온 순서대로 처리

- 비선점형(Non-Preemptive) 스케줄링

  일단 CPU를 잡으면 CPU burst가 완료될 때까지 CPU를 반환하지 않는다. 할당되었던 CPU가 반환될 때만 스케줄링이 이루어진다.

**문제점**

- Convoy Effect : 소요시간이 긴 프로세스가 먼저 도달하여 효율성을 낮추는 현상



### SJF(Shortest Job First)

**특징**

- 다른 프로세스가 먼저 도착했어도 CPU burst time이 짧은 프로세스에게 선 할당
- 비선점형(Non-Preemptive) 스케줄링

**문제점**

- Starvation : 효율성을 추구하는 게 가장 중요하지만 특정 프로세스가 지나치게 차별받으면 안되는 것이다. 이 스케줄링은 극단적으로 CPU 사용이 짧은 JOB을 선호한다. 그래서 사용시간이 긴 프로세스는 거의 영원히 CPU를 할당받을 수 없다.

### SRTF(Shortest Remaining Time First)

**특징**

- 새로운 프로세스가 도착할 때마다 새로운 스케줄링이 이루어진다.
- 선점형(Preemptive) 스케줄링 : 현재 수행중인 프로세스의 남은 burst time 보다 더 짧은 CPU burst time을 가지는 프로세스가 도착하면 CPU를 뺏긴다.

**문제점**

- Starvation
- 새로운 프로세스가 도달 할 때마다 스케줄링을 다시하기 때문에 CPU burst time(CPU 사용시간)을 측정할 수가 없다.

### Priority Scheduling

**특징**

- 우선순위가 가장 높은 프로세스에게 CPU를 할당하는 스케줄링이다. 우선순위란 정수로 표현하게 되고 작은 숫자가 우선순위가 높다.
- 선점형 스케줄링(Preemptive) 방식 : 더 높은 우선순위의 프로세스가 도착하면 실행중인 프로세스를 멈추고 CPU를 선점한다.
- 비선점형 스케줄링(Non-Preemptive) 방식 : 더 높은 우선순위의 프로세스가 도착하면 Ready Queue의 Head에 넣는다.

**문제점**

- Starvation
- 무기한 봉쇄(Indefinite blocking) : 실행 준비는 되었으나 CPU를 사용못하는 프로세스를 CPU가 무기한 대기하는 상태

**해결책**

- Aging : 아무리 우선순위가 낮은 프로세스라도 오래 기다리면 우선순위를 높여주자

### Round Robin

**특징**

- 현재적인 CPU 스케줄링
- 각 프로세스는 동일한 크기의 할당 시간(Time Quantum)을 갖게 된다.
- 할당 시간이 지나면 프로세스는 선점당하고 Ready Queue의 제일 뒤에 가서 다시 줄을 선다.
- `RR`은 CPU 사용시간이 랜덤한 프로세스들이 섞여있을 경우에 효율적
- `RR`이 가능한 이유는 프로세스의 context를 save를 할 수 있기 때문이다.

**장점**

- `Response time`이 빨라진다.

  n 개의 프로세스가 Ready Queue에 있고 할당시간이 q(Time Quantum)인 경우 각 프로세스는 q 단위로 CPU 시간의 1/N을 얻는다. 즉, 어떤 프로세스도 (N-1)q time unit 이상 기다리지 않는다.

- 프로세스가 기다리는 시간이 CPU를 사용할 만큼 증가한다. (공정한 스케줄링이라고 할 수 있다.)

**주의할점**

설정한 `time quantum`이 너무 커지면 `FCFS`와 같아진다. 또 너무 작아지면 스케줄링 알고리즘의 목적에는 이상적이지만 잦은 context switch 로 overhead 가 발생한다. 그렇기 때문에 적당한 `time quantum`을 설정하는 것이 중요하다.

## 동기와 비동기의 차이

### 비유를 통한 쉬운 설명

해야할 일이 빨래, 설거지, 청소 세 가지가 있다고 가정한다. 이 일들을 동기적으로 처리한다면 빨래를 하고 설거지를 하고 청소를 한다. 비동기적으로 일을 처리한다면 빨래하는 업체에게 빨래를 시킨다. 설거지 대행 업체에 설거지를 시킨다. 청소 대행 업체에 청소를 시킨다. 셋 중 어떤 것이 먼저 완료될지는 알 수 없다. 일을 모두 마친 업체는 나에게 알려주기로 했으니 나는 다른 작업을 할 수 있다. 이 때는 백그라운드 스레드에서 해당 작업을 처리하는 경우의 비동기를 의미한다.

**Synchronous == Blocking ? Asychronous == Non-Blocking?**

결론부터 말하자면 다르다.

동기와 비동기, Blocking 과 Non-Blocking은 각각 관심을 갖는 부분이 다르다.

### Synchronous(동기)

- 작업을 요청한 후 해당 작업의 결과가 나올 때까지 기다린 후 처리하는 것으로 I/O 작업에 대한 readliness를 기다린다. 특정 I/O 작업을 하기 위한 준비가 되었는지에 집중하는 것이다. I/O 작업 준비에 대한 이벤트의 발생을 기다렸다가 해당 이벤트가 발생하면 그에 따른 적합한 처리를 한다.

### ASynchronous(비동기)

- 작업을 요청해놓고 딴 일을 하다가 해당 작업이 오나료되면 그 때 완료되었음을 통지받고 그에 따른 작업을 처리하는 것을 말한다. I/O 작업의 완료를 기다린다. 운영체제 단계의 비동기 API를 통해 이루어지며 I/O 작업이 완료되면 그에 적합한 Handler를 이용해 처리한다.

### Blocking

- I/O가 끝날 때까지 대기해야 한다. 끝나기 전에는 함수가 반환(return)되지 않기 때문이다. 커널이 작업을 완료하기 전까지 유저 프로세스는 작업을 중단한 채 대기해야 한다. I/O작업이 CPU자원을 거의 쓰지 않기 때문에 Blocking 방법은 cpu 자원 낭비가 심하다. 즉 동기화하기 위해 blocking 하는 것이다.

### Non-Blocking

- I/O 작업을 진행하는 동안 유저 프로세스의 작업을 중단시키지 않는다. 유저 프로세스가 I/O를 처리하기 위해 커널에 함수를 호출하면, 커널에서 함수의 진행 상황과  상관없이 바로 결과를 반환한다. 이 때 반환되는 결과는 반환하는 순간에 가져올 수 있는 데이터에 해당한다. 처음에는 가져올 수 있는 데이터가 없겠지만 시간이 지나면서 가져올 수 있는 데이터가 생겨날 것이다.

Sync & Async

> 동기와 비동기는 호출되는 함수의 완료를 호출한 쪽에서 신경을 쓰냐 호출 받은 쪽에서 신경을 쓰냐의 차이다

Blocking & Non-Blocking

> Blocking 호출 받은 쪽이 호출한 쪽에 제어권을 넘겨주지 않는 것이고 Non-Blocking은 다시 제어권을 넘겨주는 것이다.

- 네가지 조합

| Sync & Blocking     | Async & Blcoking     |
| ------------------- | -------------------- |
| Sync & Non-Blocking | Async & Non-Blocking |

- Sync & Blocking

  가장 기본적으로 생각하는 Sync 이다. 함수를 호출하면 호출 받은 쪽에서 제어권을 가지고 있기 때문에 결과값이 반환 될때 까지 다음 동작을 시행 하지 않는다.

- Sync & Non-Blocking

  Non-Blocking 이라 함수가 완료 되지 않아도 제어권은 넘겨 주어 함수를 호출한 쪽에서 다음 동작을 시행 할 수는 있지만 함수가 완료되는 것을 신경을 써야하기 때문에 주기적으로 함수가 완료 되었는지 확인 해야한다.

- Async & Blocking

  잘 상상이 안 가는 그림이다. 작업완료 여부를 호출된 쪽에서 신경 쓰고 제어권도 호출된 쪽에서 가지고 있다. 사실상 Sync & Blocking과 거의 같아 잘 사용되지 않는다.

- Async & Non-blocking

  가장 기본적으로 생각하는 Async이다. 함수를 호출하면 제어권을 다시 호출 한쪽으로 넘겨주어 다음 동작을 이어 나가면서 호출 받은 쪽에서 알아서 콜백 함수의 결과를 리턴하여준다.

## 프로세스 동기화

### 임계구역(Critical Section)

> 동일한 자원을 동시에 접근하는 작업을 실행하는 코드영역
>
> 멀티 쓰레딩의 문제점이 발생

### 임계영역 문제(Critical Section Problem)

> 프로세스들이 Critical Section을 함께 사용할 수 있는 프로토콜을 설계하는 것이다. 이러한 설계를 위해서는 세가지 요구조건이 충족 되어야 한다.

**요구조건**

1. Mutual Exclusion(상호배타)
   - 프로세스 P1 이 Critical Section에서 실행중이라면, 다른 프로세스들은 그들이 가진 Critical Section에서 실행될 수 없다.
2. Progress(진행)
   - 현재 Critical Section을 사용중인 Task가 없고 Critical Section에 들어가길 원하는 Task가 있다면 바로 들여보냄
3. Bounded Waiting(한정된 대기)
   - 한정된 대기시간을 가져야 한다 => 무한 대기 X

**해결책**

#### Lock

- 하드웨어 기반 해결책으로써, 동시에 공유 자원에 접근하는 것을 막기위해 Critical Section에 진입하는 프로세스는 Lock을 획득하고 Critical Section을 빠져나올 때, Lock을 방출함으로서 동시에 접근이 되지 않도록 한다.

**한계**

- 다중처리기 환경에서는 시간적인 효율성 측면에서 적용할 수 없다.

#### Semaphores(세마포)

- 스프트웨어상에서 Critical Section 문제를 해결하기 위한 동기화 도구

**종류**

- 카운팅 세마포 : 가용한 개수를 가진 자원에 대한 접근 제어용으로 사용되며, 세마포는 그 가용한 자원의 개수로 초기화 된다. 자원을 사용하면 세마포가 감소, 방출하면 세마포가 증가한다.
- 이진 세마포 : MUTEX라도로 부르며, 상호배제의 (Mutual Exclusion)의 머릿글자를 따서 만들어졌다. 이름 그대로 0 과 1 사이의 값만 가능하며, 다중 프로세스들 사이의 Critical Section 문제를 해결하기 위해 사용한다.

**단점**

- Busy Waiting(바쁜 대기) : Spin lock이라고 불리는 Semaphore 초기 버전에서 Critical Section 에 진입해야하는 프로세스는 진입 코드를 계속 반복 실행해야 하며, CPU 시간을 낭비했었다. 이를 Busy Waiting이라고 부르며 특수한 상황이 아니면 비효율적이다. 일반적으로는 Semaphore에서 Critical Section에 진입을 시도했지만 실패한 프로세스에 대해 Block시킨 뒤, Critical Section에 자리가 날 때 다시 깨우는 방식을 사용한다. 이 경우 Busy waiting으로 인한 시간낭비 문제가 해결된다.

#### Deadlock(교착상태)

- 세마포가 Ready Queue를 가지고 있고, 둘 이상의 프로세스가 Critical Section 진입을 무한정 기다리고 있고, Critical Section 에서 실행되는 프로세스는 진입 대기중인 프로세슷가 실행되야만 빠져나올 수 있는 상황을 지칭한다.



## 가상메모리

### 가상메모리란?

> 메인 메모리의 크기가 한정되어 있기 때문에 물리적인 메모리 크기보다 큰 프로세스를 실행시킬 수 없다. 그렇다면 메인 메모리보다 크기가 큰 프로세스를 실행시키고 싶으면 어떻게 해야할까?? 그래서 나온 방법이 바로 '가상메모리'이다.

**프로세스 전체가 메모리 내에 올라오지 않더라도 실행히 가능하도록 하는 기법을 통틀어 가상메모리**라고 하며, `필요한 부분만 메모리에 올림으로써 메모리에 올라가는 프로세스의 크기를 줄이는` **요구 페이징 기법**을 사용한다. 프로세스 이미지를 모두 메모리에 올릴 필요가 없어지며, 메모리 용량 부족 이슈를 해결할 수 있다.

### 요구 페이징(Demand Paging)이란?

프로그램 실행 시작 시 **프로그램 전체를 디스크에서 물리 메모리에 적재하는 대신, 초기에 필요한 것들만 적재하는 전략**을 요구 페이징이라 하며, 가상 메모리 시스템에서 많이 사용된다.

- 가상 메모리는 대개 페이지로 관리된다.
- 요구페이징을 사용하는 가상메모리에서는 실행과정에서 필요해질 때 페이지들이 적재된다. 따라서 한번도 접근되지 않은 페이지는 물리 메모리에 적재되지 않는다.

### 가상 메모리가 하는 일

가상메모리는 실제 `물리 메모리 개념과 사용자의 논리 메모리 개념을 분리`한것이다. 따라서 작은 메모리를 가지고도 얼마든지 큰 가상주소 공간을 프로그래머에게 제공할 수 있다.

1. 시스템 라이브러리가 여러 프로세스들 사이에 공유될 수 있도록 한다. 각 프로세스들은 공유 라이브러리를 자신의 가상 주소 공간에 두고 사용하는 것처럼 인식하지만, 라이브러리가 올라가 있는 물리 메모리 페이지들은 모든 프로세스에 공유되고 있다.
2. 프로세스들이 메모리를 공유한느 것을 가능하게 하고, 프로세스들은 공유 메모리를 통해 통신할 수 있다.
3. fork()를 통한 프로세스 생산과정에서 페이지들이 공유되는 것을 가능하게 한다.

### 



---

**Reference**

- https://github.com/Seogeurim/CS-study/tree/main/contents/operating-system

- https://github.com/JaeYeopHan/Interview_Question_for_Beginner
